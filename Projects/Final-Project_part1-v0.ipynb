{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Search and Intermediation in Last Mile Shipping*\n",
    "<br>\n",
    "By **Ginha Kim** <br>\n",
    "Structural Estimation Final Project, *Winter 2019*\n",
    "***\n",
    "This project implements structural estimation (Maximum Empirical Likelihood) of the Burdett and Judd (1983) non-sequential search model. Using the methodology proposed by Hong and Shum (2006), I estimate search cost distributions with only observed prices data. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import necessary libraries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as sts\n",
    "from scipy.stats import skewnorm\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Import and Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "The data on observed prices is obtained from the third party logistics firm DAT.<br>\n",
    "The datasets provides information on spot market and contract rates for dry-van full truck loads per ton-mile.<br>\n",
    "I convert each into one-dimensional vectors of prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.1.1 ** Before loading the actual data, I simulate prices using national averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Contract Rates Simulation\n",
    "\n",
    "cr_avgs  = np.array([3.02, 2.55, 2.14, 2.35, 1.91, 1.89, 2.33])\n",
    "mean_cr  = float(np.mean(cr_avgs))\n",
    "std_cr   = float(np.std(cr_avgs))\n",
    "dum_cr   = skewnorm.rvs(0.77, loc = mean_cr , scale = std_cr, size = 1000)\n",
    "\n",
    "# Spot Market Rates Simulation\n",
    "\n",
    "sr_avgs = np.array([2.08, 1.97, 2.14, 1.86, 1.71, 1.53])\n",
    "mean_sr   = float(np.mean(sr_avgs))\n",
    "std_sr    = float(np.std(sr_avgs))\n",
    "dum_sr    = skewnorm.rvs(0.77, loc = mean_sr , scale = std_sr, size = 1000)\n",
    "\n",
    "cont_prices = np.sort(dum_cr)\n",
    "spot_prices = np.sort(dum_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.2.1 ** Simulated Contract Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = cont_prices\n",
    "mean_prices = np.mean(prices)\n",
    "med_prices  = np.median(prices)\n",
    "std_prices  = np.std(prices)\n",
    "max_prices  = np.max(prices)\n",
    "min_prices  = np.min(prices)\n",
    "print('Dummy rates ($-per-ton/mile)')\n",
    "print('Mean: ',mean_prices)\n",
    "print('Median: ',med_prices)\n",
    "print('Standard Deviation: ',std_prices)\n",
    "print('Maximum: ',max_prices)\n",
    "print('Minimum: ',min_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1.2.2 ** Simulated Spot Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = spot_prices\n",
    "mean_prices = np.mean(prices)\n",
    "med_prices  = np.median(prices)\n",
    "std_prices  = np.std(prices)\n",
    "max_prices  = np.max(prices)\n",
    "min_prices  = np.min(prices)\n",
    "print('Dummy rates ($-per-ton/mile)')\n",
    "print('Mean: ',mean_prices)\n",
    "print('Median: ',med_prices)\n",
    "print('Standard Deviation: ',std_prices)\n",
    "print('Maximum: ',max_prices)\n",
    "print('Minimum: ',min_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(cont_prices, 100, facecolor='blue' , stacked=True, label ='Simulated Contract Rates')\n",
    "n, bins, patches = plt.hist(spot_prices, 100, facecolor='green', stacked=True, label ='Simulated Spot Rates')\n",
    "plt.title('Simulated Prices Histogram') \n",
    "plt.xlabel('Dry-Van, Full-Truck-Load Rate per mile ($)')\n",
    "plt.ylabel('% of observations in bin')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. The Non-Sequential Search Model - Burdett and Judd (1983) <br>\n",
    "The following model takes from the non-seqeuntial search model specified by Burdett and Judd (1983) in their paper \"Equilibrium Price Dispersion\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   2.1 Equilibrium Conditions - Buyer side\n",
    "*Buyer's Problem* <br>\n",
    "Buyer's minimize the expected cost of acquiring the desired good by commiting to buying from the lowest priced seller over a fized number of searches (i.e. price quotations). The optimal number of searches $l^\\ast \\geq 1$ can be written as a function of per-search costs $c$ as follows: <br>\n",
    "\\begin{align}\n",
    "    l^\\ast(c) \\equiv \\underset{l>1}{arg\\min} \\quad c\\cdot(l-1) + \\int_{\\underline{p}}^{\\bar{p}} l \\cdot p(1-F_p(p))^l-1 f(p) dp \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Equilibrium Conditions - Seller side\n",
    "*Seller's Problem * <br>\n",
    "Sellers maximize their profits earned from employing the mixed pricing strategy $F_p(\\cdot)$. Let $r$ denote the common unit production cost and $\\underline{p}, \\bar{p}$ denote the lower and upper bound of the support of $F_p(\\cdot)$, respectively. \n",
    "\\par \\noindent So the seller's profit from employing the mixed pricing strategy $F_p(\\cdot)$ can be\n",
    "written as follows:\n",
    "\\begin{align}\n",
    "    \\Pi(p) = (p-r)\\bigg[\\sum_{k=1}^{\\infty}\\tilde{q_k}k(1-F_p(p))^{k-1}\\bigg] \\qquad \\text{for all  } p\\in[\\underline{p},\\bar{p}]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Structural Estimation (MEL)<br>\n",
    "The following estimation procedure follows the methodology developed by Hong and  Shum (2006) in their paper \"Using price distributions to estimate search costs\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1 Construct the Empirical Distribution of Prices $\\hat{F}_p(\\cdot)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.1** Index observations of prices in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices = cont_prices \n",
    "#prices = spot_prices\n",
    "n = prices.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices = np.sort(prices)\n",
    "#print(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.2** Fix parameters $\\underline{p}$ and $\\bar{p}$ from values obtained from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_prices = prices[0]\n",
    "max_prices = prices[n-1]\n",
    "\n",
    "#print(min_prices,max_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.3** Derive values of the empirical CDF of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ecdf(x):\n",
    "    \n",
    "    '''\n",
    "    Return empirical CDF of x\n",
    "    \n",
    "    '''\n",
    "\n",
    "    sx = np.sort(x)\n",
    "    \n",
    "    ecdf = (1.0 + np.arange(len(sx)))/len(sx)\n",
    "    \n",
    "    return ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fhat_prices = ecdf(prices)\n",
    "#plt.plot(prices,Fhat_prices)\n",
    "#print(Fhat_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Construct moment conditions from equilibrium conditions<br>\n",
    "The data consists of $n$ prices,  $p_i, i=1,...,n$. <br>\n",
    "Consider a discrete price distribution with n points of support at $p_i, \\quad i=1,...,n$.<br>\n",
    "<br>\n",
    " \\begin{align}\n",
    "          F_p(p) = \\sum_{i=1}^{n} \\pi_{i} \\mathbf{1}(p_i\\leq p)\\qquad i=1,...,n\n",
    "  \\end{align}\n",
    "  <br>\n",
    " where $\\pi_i$ denotes the probability weight at point $p_i$.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the indifference conditions we derived from the equilibrium restrictions described above: <br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    (\\bar{p}-r)\\tilde{q_1} = (p_i-r)\\bigg[\\sum_{k=1}^K \\tilde{q_k}k(1-\\hat{F}_p(p_i))^{k-1}\\bigg] \\qquad i = 1,...,n-1\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all $i=1,...,n-1$ and fixed $K$, the distrcete distritbution $F_p(\\cdot)$ analogously yields:<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    (\\bar{p}-r)\\tilde{q_1} = (p_i-r)\\bigg[\\sum_{k=1}^K \\tilde{q_k}k\\bigg(1-\\bigg[\\sum_{j=1}^{n} \\pi_j \\mathbf{1}(p_j\\leq p_i)\\bigg]\\bigg)\\bigg] \\qquad i = 1,...,n-1 \\quad \\cdot\\cdot\\cdot\\quad (1)\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\theta \\equiv \\{r,\\tilde{q_1},....,\\tilde{q}_K\\}$ denote the unknown parameters to be estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.1** Define necessary values including random sample of ECDF values $s_m \\in [0,1], \\quad m = 1,...,M, \\quad M\\geq K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "M = K + 3\n",
    "dS  = np.sort(np.random.choice(Fhat_prices, size = M, replace = False))\n",
    "print(dS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.2.2 ** Define functions that generates values for function variables<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    \\sum_{k=1}^K \\tilde{q_k}k\n",
    "\\end{align}\n",
    "<br>\n",
    "\\begin{align}\n",
    "    \\sum_{k=1}^K \\tilde{q_k}k(1-s_m)^{k-1}\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_qkk_gen(q):\n",
    "    \n",
    "    qkk = np.zeros(K)\n",
    "    \n",
    "    for i in range(K):\n",
    "        \n",
    "        qkk[i] = q[i] * (i+1)\n",
    "        \n",
    "    return np.sum(qkk)\n",
    "\n",
    "def sum_qks_gen(q, s):\n",
    "    \n",
    "    qks = np.zeros(K)\n",
    "    \n",
    "    for i in range(K):\n",
    "        \n",
    "        qks[i] = q[i] * (i+1) * ((1 - s) ** i)\n",
    "        \n",
    "    return np.sum(qks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.2.3 ** Define $r$ as a function of $\\underline{p},\\bar{p},\\text{ and } \\mathbf{\\tilde{q}} \\equiv [\\tilde{q}_1,...,\\tilde{q}_K]$ <br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    r(\\tilde{\\mathbf{q}}) \\equiv \\frac{\\underline{p}\\cdot\\big[\\sum_{k=1}^K \\tilde{q_k}k\\big]-\\bar{p}\\cdot\\tilde{q_1}}{\\big[\\sum_{k=1}^K \\tilde{q_k}k\\big]-\\tilde{q_1}}\n",
    "\\end{align}\n",
    "<br>\n",
    "where $\\underline{p}$ and $\\bar{p}$ are given by the data and treated as known and nonstocastic parameters.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r_gen(prices, q):\n",
    "    \n",
    "    n = prices.size\n",
    "    prices = np.sort(prices)\n",
    "    min_p = prices[0]\n",
    "    max_p = prices[n-1]\n",
    "    \n",
    "    numerator = (min_p * sum_qkk_gen(q)) - (max_p * q[0])\n",
    "    \n",
    "    denominator = sum_qkk_gen(q) - q[0]\n",
    "    \n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.4** Define a funtion that generates $s_m$th quantile of $F_p(\\cdot)$<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "& \\Rightarrow F_p^{-1}(s_m) = r(\\tilde{\\mathbf{q}}) + \\frac{(\\bar{p}-r(\\tilde{\\mathbf{q}}))\\tilde{q_1}}{\\sum_{k=1}^K \\tilde{q_k}k(1-s_m)^{k-1}} \\equiv g_{s_m}(\\tilde{\\mathbf{q}})\n",
    "\\end{align}\n",
    "<br>\n",
    "\\begin{align}\n",
    "& \\Rightarrow s_m\\text{th quantile of } F_p(p) = g_{s_m}(\\tilde{\\mathbf{q}})\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g_gen(prices, q, s):\n",
    "    \n",
    "    n = prices.size\n",
    "    prices = np.sort(prices)\n",
    "    min_p = prices[0]\n",
    "    max_p = prices[n-1]\n",
    "\n",
    "    num   = (max_p  - r_gen(prices, q)) * q[0]\n",
    "    \n",
    "    denom = sum_qks_gen(q, s)\n",
    "    \n",
    "    g = r_gen(prices, q) + (num / denom)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Maximum Empirical Likelihood - Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population quantile restriction can be rewritten as a population mean restriction:<br>\n",
    "<br>\n",
    "\\begin{align*}\n",
    "    E\\bigg[\\mathbf{1}\\bigg(p_i \\leq  r(\\tilde{\\mathbf{q}}) + \\frac{(\\bar{p}-r(\\tilde{\\mathbf{q}}))\\tilde{q_1}}{\\sum_{k=1}^K \\tilde{q_k}k(1-s_m)^{k-1}} \\bigg)-s_m\\bigg] = 0, \\qquad m = 1,...,M, \\quad M \\geq K\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample analogs of the population mean restrictions can be derived as follows:<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    \\sum_{j=1}^{n} \\pi_j \\cdot \\bigg[\\mathbf{1}\\bigg(p_i \\leq  r(\\tilde{\\mathbf{q}}) + \\frac{(\\bar{p}-r(\\tilde{\\mathbf{q}}))\\tilde{q_1}}{\\sum_{k=1}^K \\tilde{q_k}k(1-s_m)^{k-1}} \\bigg)-s_m \\bigg] = 0  \\quad \\cdot\\cdot\\cdot\\cdot\\cdot \\quad (2)\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the empirical likelihood problem with respect to weights $\\pi_i$ for $i=1,...,n$ and parameters $\\theta$ can be written as follows:<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    & \\underset{\\theta}{\\max} \\sum_{i=1}^{n} \\log \\pi_i \\quad\n",
    "    s.t. \\quad \\sum_{i=1}^{n} \\pi_i = 1 \n",
    "\\end{align}\n",
    "<br>\n",
    "subject to the sample moment conditions in (1) and the summing-up condition.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.3.1 ** Define a function that calculates values of the indicator function<br>\n",
    "<br>\n",
    "\\begin{align}\n",
    "    \\mathbf{1}\\bigg(p_i \\leq  p \\bigg)\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_indc(pi, p):\n",
    "    \n",
    "    if pi < p:\n",
    "        p_indc = 1\n",
    "        \n",
    "    elif pi == p:\n",
    "        p_indc = 1\n",
    "        \n",
    "    elif pi > p:\n",
    "        p_indc = 0\n",
    "        \n",
    "    return p_indc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.3.2 ** Define a function that calculates the sum of probability weights $\\pi_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\\begin{align}\n",
    "    \\sum_{i=1}^{n} \\pi_i = 1 \n",
    "\\end{align}\n",
    "<br>\n",
    "$\\pi_i$ denotes the probability weight at the point $p_i, i = 1,...,n$ where $p_i$'s are the $n$ points of support of the discrete price distibution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_vec_gen(prices, Fhat):\n",
    "    \n",
    "    n = prices.size\n",
    "    weights = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        weights[0] = Fhat[0] - 0\n",
    "        weights[i] = Fhat[i] - Fhat[i-1]\n",
    "    \n",
    "    return weights\n",
    "\n",
    "#print(weight_vec_gen(prices,Fhat_prices))\n",
    "#print(np.sum(weight_vec_gen(prices,Fhat_prices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.3.4 ** Define a function that generates $F_p(\\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\\begin{align}\n",
    "          F_p(p) = \\sum_{i=1}^{n} \\pi_{i} \\mathbf{1}(p_i\\leq p)\\qquad i=1,...,n\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def F_p_gen(prices, p, Fhat):\n",
    "    \n",
    "    n = prices.size\n",
    "    \n",
    "    prob_vec = np.zeros(n)\n",
    "    \n",
    "    weights = weight_vec_gen(prices, Fhat)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        pi = prices[i]\n",
    "        \n",
    "        wi = weights[i]\n",
    "        \n",
    "        prob_vec[i] = wi * p_indc(pi, p)\n",
    "            \n",
    "    prob = np.sum(prob_vec)\n",
    "\n",
    "    return prob\n",
    "\n",
    "#dindex = np.where(prices == dp)[0]\n",
    "#print(dindex)\n",
    "#print(dp)\n",
    "#print(Fhat_prices[dindex])\n",
    "#print(F_p_gen(prices, dp, Fhat_prices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.3.5 ** Generate $M$ moment conditions by iterating process over $M$ values of $s$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sanple Analog Moment Conditions:*\n",
    "<br>\n",
    "\\begin{align}\n",
    "    \\sum_{j=1}^{n} \\pi_j \\cdot \\bigg[\\mathbf{1}\\bigg(p_j \\leq  r(\\tilde{\\mathbf{q}}) + \\frac{(\\bar{p}-r(\\tilde{\\mathbf{q}}))\\tilde{q_1}}{\\sum_{k=1}^K \\tilde{q_k}k(1-s_m)^{k-1}} \\bigg)-s_m \\bigg] = 0  \\quad \\cdot\\cdot\\cdot\\cdot\\cdot \\quad (2)\n",
    "\\end{align}\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mom_gen(pi, q, S):\n",
    "    \n",
    "    M     = S.size\n",
    "    mom_vec   = np.zeros(M)\n",
    "    \n",
    "    for m in range(M):\n",
    "        \n",
    "        sm = S[m]\n",
    "        \n",
    "        gq = g_gen(prices, q, sm)\n",
    "        \n",
    "        mom_vec[m] = p_indc(pi, gq) - sm\n",
    "        \n",
    "    return mom_vec\n",
    "#print(mom_Fp_gen(dq, prices, dp, ds, Fhat_prices, min_prices, max_prices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Maximum Empirical Likelihood - Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.4.1 ** Construct the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj_func_gen(t, q, prices, S, Fhat):\n",
    "    \n",
    "    n     = prices.size\n",
    "    min_p = prices[0]\n",
    "    max_p = prices[n-1]\n",
    "    \n",
    "    weights = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        pi = prices[i]\n",
    "            \n",
    "        mom = mom_gen(pi, q, S)\n",
    "\n",
    "        weights[i] = 1 + np.dot(t,mom)\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.4.2 ** Define the criterion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def criterion(params, *args):\n",
    "    \n",
    "    t, q = params\n",
    "    \n",
    "    prices, S, Fhat = args\n",
    "    \n",
    "    ppf_vals     = obj_func_gen(t, q, prices, S, Fhat)\n",
    "    log_ppf_vals = np.log(ppf_vals)\n",
    "    log_like_val = log_ppf_vals.sum()\n",
    "    neg_log_like = -log_like_val\n",
    "    \n",
    "    return neg_log_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.4.3 ** Construct the minimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    & \\underset{\\theta}{\\max} \\quad \\underset{t}{\\min}\\quad \\sum_{i=1}^{n}\\log \\bigg(1+ t'\\bigg[\\mathbf{1}\\bigg(p_i \\leq  r(\\tilde{\\mathbf{q}}) + \\frac{(\\bar{p}-r(\\tilde{\\mathbf{q}}))\\tilde{q_1}}{\\sum_{k=1}^K \\tilde{q_k}k(1-s_m)^{k-1}} \\bigg)-s_m \\bigg]\n",
    "    \\bigg)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial Values\n",
    "#q_init = np.zeros(K) + (1/K)\n",
    "q_init = np.array([0.4,0.3,0.2,0.1,0])\n",
    "t_init = np.zeros(M)\n",
    "params_init = np.array([t_init, q_init])\n",
    "\n",
    "# Boundaries \n",
    "#q_bounds = [(1e-10,1),(1e-10,1),(1e-10,1),(1e-10,1),(1e-10,1)]\n",
    "#t_bounds = [(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None)]\n",
    "#param_bounds = [(1e-10,1),(1e-10,None)]\n",
    "#param_bounds    = (t_bounds, q_bounds)\n",
    "#param_bounds= ((1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),(1e-10,None),\n",
    "              # (1e-10,1),(1e-10,1),(1e-10,1),(1e-10,1),(1e-10,1))\n",
    "\n",
    "# Constraints\n",
    "#cons = ({'type': 'eq', 'fun' : lambda q: np.array([q[0]+q[1]+q[2]+q[3]+q[4]+q[5]-1])})\n",
    "\n",
    "# MEL Arguments\n",
    "mel_args = prices, dS, Fhat_prices\n",
    "n = prices.size\n",
    "\n",
    "#results  = opt.minimize(criterion, params_init, args = (mel_args), method='BFGS', options = {'gtol': 1e-7 * n, 'disp': True})\n",
    "\n",
    "#results  = opt.minimize(criterion, params_init, args = (mel_args), method='L-BFGS-B', bounds = param_bounds, \n",
    "                        #options = {'gtol': 1e-7 * n, 'disp': True})\n",
    "#results  = opt.minimize(criterion, params_init, args = (mel_args), method='SLSQP', bounds = param_bounds, constraints = cons, \n",
    "                        #options = {'gtol': 1e-7 * n, 'disp': True})\n",
    "#results  = opt.minimize(criterion, params_init, args = (mel_args), method='CG', options = {'gtol': 1e-7 * n, 'disp': True})\n",
    "#results  = opt.minimize(criterion, params_init, args = (mel_args), method='TNC', options = {'gtol': 1e-7 * n, 'disp': True})\n",
    "\n",
    "print(results)\n",
    "q_mele = np.array(results.x)[1]\n",
    "r_mele = r_gen(spot_prices, q_mele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estimate the distribution of Search Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.1** Define a function to recover the cut-off values at indiffence points of the distribution of search costs.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    \\tilde{q_k} = F_c(\\Delta_{k-1})-F_c(\\Delta_{k}) = \\text{the proportion of buyers with $k$ price quotes}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_c_gen(q):\n",
    "    \n",
    "    K = q.size\n",
    "    \n",
    "    F_c_gen = np.zeros(K)\n",
    "    \n",
    "    qsum = []\n",
    "    \n",
    "    for i in range(K):\n",
    "        \n",
    "        F_c_gen[0] = 1 - q[0] \n",
    "        \n",
    "        F_c_gen[i] = 1- np.sum(q[:i+1])\n",
    "        \n",
    "        F_c_gen[K-1] = 0\n",
    "        \n",
    "    return F_c_gen\n",
    "\n",
    "print(F_c_gen(cdq))\n",
    "print(F_c_gen(sdq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.2 ** Define a function that calcalates the expected value of the lowest among random draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    Ep_{1:i} = \\underline{p} + \\int_{\\underline{p}}^{\\bar{p}} (1-F_p(p))^i dp\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_p_gen(prices, Fhat, K):\n",
    "    \n",
    "    prices = np.sort(prices)\n",
    "    n = prices.size\n",
    "    min_p = prices[0]\n",
    "    max_p = prices[n-1]\n",
    "    E_p = np.zeros(K)\n",
    "    \n",
    "    for i in range(1, K+1):\n",
    "        \n",
    "        E_p[0]       = max_p\n",
    "        iprice_draws = np.random.choice(prices, size = i, replace = False )\n",
    "        price_draws  = np.sort(iprice_draws)\n",
    "        lowest_price = price_draws[0]\n",
    "        upper_index  = np.where(prices == lowest_price)[0] + 1\n",
    "        lower_index  = np.where(prices == lowest_price)[0] - 1\n",
    "        middle_index = np.where(prices == lowest_price)[0]\n",
    "        prob_choice  = Fhat[upper_index] - Fhat[lower_index]\n",
    "        prob_min     = ((1-Fhat[middle_index]) ** i)\n",
    "        \n",
    "        \n",
    "        E_p[i-1]       = min_p + lowest_price * prob_choice * prob_min\n",
    "        E_p[K-1] = min_p\n",
    "        \n",
    "    return E_p\n",
    "\n",
    "print(E_p_gen(cont_prices, Fhat_cont, 5))\n",
    "print(E_p_gen(spot_prices, Fhat_spot, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.3** Define a function that recovers indifference points from the cumulative distribution of search costs. <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\Delta_i \\equiv Ep_{1:i}-Ep_{1:i+1} \\qquad i = 1,2,...,\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_gen(prices, Fhat, K):\n",
    "    \n",
    "    prices = np.sort(prices)\n",
    "    n = prices.size\n",
    "    min_p = prices[0]\n",
    "    max_p = prices[n-1]\n",
    "    \n",
    "    delta = np.zeros(K)\n",
    "    \n",
    "    E_p = E_p_gen(prices, Fhat, K)\n",
    "    \n",
    "    for i in range(K-1):\n",
    "        \n",
    "        delta[0] = E_p[0] - E_p[1]\n",
    "        delta[i] = E_p[i] - E_p[i+1]\n",
    "        delta[i] = 100 * round(delta[i], 4)\n",
    "        \n",
    "    \n",
    "    return delta\n",
    "\n",
    "print(delta_gen(cont_prices, Fhat_cont, 5))\n",
    "print(delta_gen(spot_prices, Fhat_spot, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.4 ** Plot the distribution of search costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_delta = delta_gen(cont_prices, Fhat_cont, 5)\n",
    "spot_delta = delta_gen(spot_prices, Fhat_spot, 5)\n",
    "X          = np.linspace(0,3,6)\n",
    "\n",
    "\n",
    "F_cc   = F_c_gen(cdq)\n",
    "F_cs   = F_c_gen(sdq)\n",
    "FF_cc  = np.append(F_cc[::-1],np.ones(1))\n",
    "FF_cs  = np.append(F_cs[::-1],np.ones(1))\n",
    "print(FF_cc)\n",
    "print(FF_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(cont_delta, F_cc, linewidth=2, color ='c', label = 'Contracts $F_c(\\cdot)$')\n",
    "plt.plot(spot_delta, F_cs, linewidth=2, color ='g', label = 'Spot Market $F_c(\\cdot)$')\n",
    "#xcoords = np.sort(spot_delta)\n",
    "#for xc in xcoords:\n",
    "plt.axvline(x= cont_delta[0], linestyle='--',linewidth=0.7,color ='c')\n",
    "plt.axvline(x= cont_delta[3], linestyle='--',linewidth=0.7,color ='c')\n",
    "plt.axvline(x= spot_delta[0], linestyle='--',linewidth=0.7,color ='g')\n",
    "plt.axvline(x= spot_delta[3], linestyle='--',linewidth=0.7,color ='g')\n",
    "plt.annotate('$\\Delta_1$', xy = (0.01+cont_delta[0],0.9), color = 'c',fontsize = 8)\n",
    "plt.annotate('$\\Delta_4$', xy = (0.01+cont_delta[3],0.9), color = 'c',fontsize = 8)\n",
    "plt.annotate('$\\Delta_1$', xy = (0.01+spot_delta[0],0.9), color = 'g',fontsize = 8)\n",
    "plt.annotate('$\\Delta_4$', xy = (0.01+spot_delta[3],0.9), color = 'g',fontsize = 8)\n",
    "#xcoords = np.sort(cont_delta)\n",
    "#for xc in xcoords:\n",
    "    #plt.axvline(x=xc, linestyle='--')\n",
    "#cp1, = plt.plot(cont_prices.mean(),0.5, marker='o', markersize=3, color=\"r\")\n",
    "#sp1, = plt.plot(spot_prices.mean(),0.5, marker='o', markersize=3, color=\"g\")\n",
    "#plt.plot(X, FF_cc, linewidth=2, color ='r', label = '$Contracts F_c(\\cdot)$')\n",
    "#plt.plot(X, FF_cs, linewidth=2, color ='g', label = '$Spot Market F_c(\\cdot)$')\n",
    "#plt.plot(prices, Fhat_prices, linewidth=2, color ='r', label = '$F_p(\\cdot)$')\n",
    "#p1, = plt.plot(prices[0],0.5, marker='o', markersize=3, color=\"red\")\n",
    "#p2, = plt.plot(mean_delta,0.5, marker='o', markersize=3, color=\"blue\")\n",
    "#p3, = plt.plot(prices[n-1],0.95, marker='o', markersize=3, color=\"red\")\n",
    "#plt.legend([p1,p2,p3], [\"Min p\",\"Max p\",\"$\\bar{c}$\"])\n",
    "#plt.xlim(-1e-10,3.8)\n",
    "plt.ylim(0,1)\n",
    "plt.title('Estimated Search Cost Distribution', fontsize = 12,fontweight = 'semibold',linespacing =2)\n",
    "plt.xlabel('c = Cost per Search ($)')\n",
    "plt.ylabel('Estimated Search Cost CDF')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
